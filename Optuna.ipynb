{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48584baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import warnings\n",
    "from numpy import savetxt\n",
    "from numpy import loadtxt\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac695b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "import optuna\n",
    "from sklearn.ensemble import BaggingRegressor,AdaBoostRegressor,GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.svm import SVR\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4978b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = loadtxt('Data_Set/train.csv', delimiter=',')\n",
    "label = loadtxt('Data_Set/label.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2bdcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983ef489",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train, label, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4785ab8",
   "metadata": {},
   "source": [
    "# Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2868aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bossting_objectiveDecisionTreeRegressor(trail):\n",
    "    result=[]\n",
    "    random_state=42\n",
    "    losses=['squared_error', 'absolute_error', 'huber', 'quantile']\n",
    "    min_samples_split=trail.suggest_float('min_samples_split',0.001,1.0)\n",
    "    number_of_splits=trail.suggest_int('number_of_splits',4,7)\n",
    "    random_state=trail.suggest_int('random_state',4,50)\n",
    "    min_samples_leaf=trail.suggest_float('min_samples_leaf',0.001,0.5)\n",
    "    min_weight_fraction_leaf=trail.suggest_float('min_weight_fraction_leaf',0.0,0.5)\n",
    "    min_impurity_decrease=trail.suggest_float('min_impurity_decrease',0.0,0.5)\n",
    "    ccp_alpha=trail.suggest_float('ccp_alpha',0.0,10.5)\n",
    "\n",
    "\n",
    "    max_depth=trail.suggest_int('max_depth',2,50)\n",
    "    k_fold=KFold(n_splits=number_of_splits)\n",
    "\n",
    "    params={x:y for (x,y) in trail.params.items() if x!='number_of_splits'}\n",
    "    result=[]\n",
    "    for tr, tst in k_fold.split(train,label):\n",
    "        xgb_reg = DecisionTreeRegressor(**params)\n",
    "        X_train, X_test, y_train, y_test = train[tr],train[tst],label[tr],label[tst]\n",
    "        xgb_reg.fit(X_train, y_train)\n",
    "        # Handle pruning based on the intermediate value.\n",
    "        if trail.should_prune():\n",
    "            print(\"Handle pruning based on the intermediate value.\")\n",
    "            raise optuna.TrialPruned()\n",
    "\n",
    "        result.append(round(r2_score(y_test,xgb_reg.predict(X_test)),4))\n",
    "            \n",
    "    return np.average(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb721c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bossting_objectiveAdaBoostRegressor(trail):\n",
    "    result=[]\n",
    "    n_estimators = trail.suggest_int('n_estimators',1,50)\n",
    "    learning_rate=trail.suggest_float(\"learning_rate\", 1e-3, 1e-1,log=True)\n",
    "    random_state= trail.suggest_int('random_state',1,100)\n",
    "\n",
    "    number_of_splits=trail.suggest_int('number_of_splits',4,7)\n",
    "    k_fold=KFold(n_splits=number_of_splits)\n",
    "    params={x:y for (x,y) in trail.params.items() if x!='number_of_splits'}\n",
    "    for tr, tst in k_fold.split(train,label):\n",
    "        reg = AdaBoostRegressor(**params)\n",
    "        X_train, X_test, y_train, y_test = train[tr],train[tst],label[tr],label[tst]\n",
    "        reg.fit(X_train, y_train)\n",
    "        result.append(round(r2_score(y_test,reg.predict(X_test)),4))\n",
    "            \n",
    "    return np.average(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76d1c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bossting_objectiveCatBoostRegressor(trail):\n",
    "    result=[]\n",
    "    \n",
    "    iterations = trail.suggest_int('iterations',3000,40000)\n",
    "    learning_rate=trail.suggest_float(\"learning_rate\", 1e-3, 1e-1,log=True)\n",
    "    depth=trail.suggest_int('depth',2,16)\n",
    "    random_seed = trail.suggest_int('random_seed',50,500)\n",
    "    metric_period = trail.suggest_int('metric_period',100,500)\n",
    "    od_wait = trail.suggest_int('od_wait',10,150)\n",
    "    \n",
    "\n",
    "    params={x:y for (x,y) in trail.params.items() if x!='number_of_splits'}\n",
    "    params['loss_function'] = 'RMSE'\n",
    "    params['eval_metric'] = 'RMSE'\n",
    "    params['od_type'] = 'Iter'\n",
    "    params['use_best_model'] = True\n",
    "    params['verbose'] = False\n",
    "    result=[]\n",
    "    number_of_splits=trail.suggest_int('number_of_splits',4,7)\n",
    "    k_fold=KFold(n_splits=number_of_splits)\n",
    "    for tr, tst in k_fold.split(train,label):\n",
    "\n",
    "\n",
    "        model_regressor = CatBoostRegressor(**params)\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train[tr],train[tst],label[tr],label[tst]\n",
    "        model_regressor.fit(X_train, y_train, \n",
    "          eval_set=(X_test, y_test),  \n",
    "          use_best_model=True,  \n",
    "          plot= False   \n",
    "         );\n",
    "        \n",
    "        # Handle pruning based on the intermediate value.\n",
    "        if trail.should_prune():\n",
    "            print(\"Handle pruning based on the intermediate value.\")\n",
    "            raise optuna.TrialPruned()\n",
    "\n",
    "        result.append(round(r2_score(y_test,model_regressor.predict(X_test)),4))\n",
    "            \n",
    "    return np.average(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f30d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bossting_objectiveKNeighborsRegressor(trail):\n",
    "    result=[]\n",
    "    n_neighbors = trail.suggest_int('n_neighbors',1,50)\n",
    "    leaf_size= trail.suggest_int('leaf_size',1,100)\n",
    "    p= trail.suggest_int('p',1,2)\n",
    "    n_jobs = trail.suggest_int('n_jobs',2,8)\n",
    "\n",
    "\n",
    "    number_of_splits=trail.suggest_int('number_of_splits',4,7)\n",
    "    k_fold=KFold(n_splits=number_of_splits)\n",
    "    params={x:y for (x,y) in trail.params.items() if x!='number_of_splits'}\n",
    "    for tr, tst in k_fold.split(train,label):\n",
    "        reg = KNeighborsRegressor(n_neighbors=3,leaf_size=leaf_size,p=p,n_jobs=n_jobs)\n",
    "        X_train, X_test, y_train, y_test = train[tr],train[tst],label[tr],label[tst]\n",
    "        reg.fit(X_train, y_train)\n",
    "        result.append(round(r2_score(y_test,reg.predict(X_test)),4))\n",
    "            \n",
    "    return np.average(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57414776",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bossting_objectiveRandomForestRegressor(trail):\n",
    "    random_state=42\n",
    "    losses=['squared_error', 'absolute_error', 'huber', 'quantile']\n",
    "    criterions=['friedman_mse', 'squared_error']\n",
    "    criterion=trail.suggest_categorical('criterion',criterions)\n",
    "    n_estimators=trail.suggest_int('n_estimators',50,500)\n",
    "    min_samples_leaf=trail.suggest_float('min_samples_leaf',0.001,0.5)\n",
    "    min_samples_split=trail.suggest_float('min_samples_split',0.001,1.0)\n",
    "    min_weight_fraction_leaf=trail.suggest_float('min_weight_fraction_leaf',0.001,0.5)\n",
    "    max_depth=trail.suggest_int('max_depth',2,50)\n",
    "    n_jobs = trail.suggest_int('n_jobs',2,4)\n",
    "#     verbose= trail.suggest_int('verbose',1,100)\n",
    "    ccp_alpha=trail.suggest_float('ccp_alpha',0.5,0.9)\n",
    "#     min_impurity_decrease=trail.suggest_float('min_impurity_decrease',0.001,100.0)\n",
    "    \n",
    "    number_of_splits=trail.suggest_int('number_of_splits',4,7)\n",
    "    k_fold=KFold(n_splits=number_of_splits)\n",
    "    params={x:y for (x,y) in trail.params.items() if x!='number_of_splits'}\n",
    "    result=[]\n",
    "    for tr, tst in k_fold.split(train,label):\n",
    "        reg=RandomForestRegressor(**params)\n",
    "        X_train, X_test, y_train, y_test = train[tr],train[tst],label[tr],label[tst]\n",
    "        reg.fit(X_train, y_train)\n",
    "        result.append(round(r2_score(y_test,reg.predict(X_test)),4))\n",
    "    return np.average(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284abd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bossting_objectiveSVR(trail):\n",
    "    result=[]\n",
    "    coef0 = trail.suggest_float(\"coef0\", 0.0, 10.0)\n",
    "    tol = trail.suggest_float(\"tol\", 0.001, 1.0)\n",
    "    epsilon = trail.suggest_float(\"epsilon\", 0.1, 10.0)\n",
    "    C = trail.suggest_float(\"C\", 1.0, 10.0)\n",
    "    degree = trail.suggest_int('degree',3,10)\n",
    "    max_iter = trail.suggest_int('max_iter',-1,100)\n",
    "    cache_size = trail.suggest_int('cache_size',10,400)\n",
    "\n",
    "    params={x:y for (x,y) in trail.params.items() if x!='number_of_splits'}\n",
    "    result=[]\n",
    "    number_of_splits=trail.suggest_int('number_of_splits',4,7)\n",
    "    k_fold=KFold(n_splits=number_of_splits)\n",
    "    for tr, tst in k_fold.split(train,label):\n",
    "        xgb_reg=SVR(**params)\n",
    "        X_train, X_test, y_train, y_test = train[tr],train[tst],label[tr],label[tst]\n",
    "        xgb_reg.fit(X_train, y_train)\n",
    "        # Handle pruning based on the intermediate value.\n",
    "        if trail.should_prune():\n",
    "            print(\"Handle pruning based on the intermediate value.\")\n",
    "            raise optuna.TrialPruned()\n",
    "\n",
    "        result.append(round(r2_score(y_test,xgb_reg.predict(X_test)),4))\n",
    "            \n",
    "    return np.average(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5ff248",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bossting_objectiveGradientBoostingRegressor(trail):\n",
    "    result=[]\n",
    "    learning_rate=trail.suggest_float(\"learning_rate\", 1e-3, 1e-1,log=True)\n",
    "    random_state=42\n",
    "    losses=['squared_error', 'absolute_error', 'huber', 'quantile']\n",
    "    # max_features=trail.suggest_float('max_features',0.001,1.0)\n",
    "    alpha=trail.suggest_float('alpha',0.5,0.9)\n",
    "    # ccp_alpha=trail.suggest_float('ccp_alpha',0.0,1)\n",
    "    criterions=['friedman_mse', 'squared_error']\n",
    "    loss=trail.suggest_categorical('loss',losses)\n",
    "    criterion=trail.suggest_categorical('criterion',criterions)\n",
    "    n_estimators=trail.suggest_int('n_estimators',50,500)\n",
    "    number_of_splits=trail.suggest_int('number_of_splits',4,7)\n",
    "    # subsample=trail.suggest_float('subsample',0.001,1.0)\n",
    "    min_samples_leaf=trail.suggest_float('min_samples_leaf',0.001,0.5)\n",
    "    min_samples_split=trail.suggest_float('min_samples_split',0.001,1.0)\n",
    "    min_weight_fraction_leaf=trail.suggest_float('min_weight_fraction_leaf',0.001,0.5)\n",
    "    max_depth=trail.suggest_int('max_depth',2,50)\n",
    "    min_impurity_decrease=trail.suggest_float('min_impurity_decrease',0.001,100.0)\n",
    "    k_fold=KFold(n_splits=number_of_splits)\n",
    "    params={x:y for (x,y) in trail.params.items() if x!='number_of_splits'}\n",
    "    result=[]\n",
    "    for tr, tst in k_fold.split(train,label):\n",
    "        reg=GradientBoostingRegressor(random_state=random_state,**params)\n",
    "        X_train, X_test, y_train, y_test = train[tr],train[tst],label[tr],label[tst]\n",
    "        reg.fit(X_train, y_train)\n",
    "        result.append(round(r2_score(y_test,reg.predict(X_test)),4))\n",
    "            \n",
    "    return np.average(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae03171",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abc9c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna_Array = [bossting_objectiveAdaBoostRegressor,bossting_objectiveGradientBoostingRegressor,\n",
    "                bossting_objectiveKNeighborsRegressor,bossting_objectiveSVR,bossting_objectiveCatBoostRegressor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff8c0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_array = []\n",
    "for item in optuna_Array:\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(item, n_trials=1000)\n",
    "    study_array.append(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0bdd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in study_array:\n",
    "    print('r2: ' + str(item.best_value))\n",
    "    print('Best parameter: ' + str(item.best_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bf6fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna_Array[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8ec891",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8828ba18",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in study_array:\n",
    "    fig = optuna.visualization.plot_param_importances(item)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b775cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
